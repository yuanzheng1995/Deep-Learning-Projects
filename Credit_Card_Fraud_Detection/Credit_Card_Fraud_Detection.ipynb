{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab78191-56b2-4dc6-a84e-ccf818038c9a",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6fad9a-840b-4db4-8848-13079cffb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "import gc\n",
    "from datetime import datetime \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "RFC_METRIC = 'gini'  #metric used for RandomForrestClassifier\n",
    "NUM_ESTIMATORS = 100 #number of estimators used for RandomForrestClassifier\n",
    "NO_JOBS = 4 #number of parallel jobs used for RandomForrestClassifier\n",
    "\n",
    "\n",
    "#TRAIN/VALIDATION/TEST SPLIT\n",
    "#VALIDATION\n",
    "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "\n",
    "#CROSS-VALIDATION\n",
    "NUMBER_KFOLDS = 5 #number of KFolds for cross-validation\n",
    "\n",
    "\n",
    "\n",
    "RANDOM_STATE = 2018\n",
    "\n",
    "MAX_ROUNDS = 1000 #lgb iterations\n",
    "EARLY_STOP = 50 #lgb early stop \n",
    "OPT_ROUNDS = 1000  #To be adjusted based on best validation rounds\n",
    "VERBOSE_EVAL = 50 #Print out metric result\n",
    "\n",
    "IS_LOCAL = False\n",
    "\n",
    "import os\n",
    "\n",
    "if(IS_LOCAL):\n",
    "    PATH=\"../input/credit-card-fraud-detection\"\n",
    "else:\n",
    "    PATH=\"../input\"\n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433fc440-a28d-4a01-a33c-3fa163caaeb0",
   "metadata": {},
   "source": [
    "## Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9345b-3647-4cf3-bc58-29e5602867ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(PATH+\"/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b7c95-f322-49be-8f6f-3c602c2ca052",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Credit Card Fraud Detection data -  rows:\",data_df.shape[0],\" columns:\", data_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb618f7d-2f22-4cf5-99c8-d54afcd78a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdafe81-c2ab-492b-b239-a526cfad4141",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data unbalance\n",
    "temp = data_df[\"Class\"].value_counts()\n",
    "df = pd.DataFrame({'Class': temp.index,'values': temp.values})\n",
    "\n",
    "trace = go.Bar(\n",
    "    x = df['Class'],y = df['values'],\n",
    "    name=\"Credit Card Fraud Class - data unbalance (Not fraud = 0, Fraud = 1)\",\n",
    "    marker=dict(color=\"Red\"),\n",
    "    text=df['values']\n",
    ")\n",
    "data = [trace]\n",
    "layout = dict(title = 'Credit Card Fraud Class - data unbalance (Not fraud = 0, Fraud = 1)',\n",
    "          xaxis = dict(title = 'Class', showticklabels=True), \n",
    "          yaxis = dict(title = 'Number of transactions'),\n",
    "          hovermode = 'closest',width=600\n",
    "         )\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f40735b-92cb-47dc-8484-a9bfeae98132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = data_df.loc[data_df['Class'] == 0][\"Time\"]\n",
    "class_1 = data_df.loc[data_df['Class'] == 1][\"Time\"]\n",
    "\n",
    "hist_data = [class_0, class_1]\n",
    "group_labels = ['Not Fraud', 'Fraud']\n",
    "\n",
    "fig = ff.create_distplot(hist_data, group_labels, show_hist=False, show_rug=False)\n",
    "fig['layout'].update(title='Credit Card Transactions Time Density Plot', xaxis=dict(title='Time [s]'))\n",
    "iplot(fig, filename='dist_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae4399-4114-4c96-acf1-613a52fd20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Hour'] = data_df['Time'].apply(lambda x: np.floor(x / 3600))\n",
    "\n",
    "tmp = data_df.groupby(['Hour', 'Class'])['Amount'].aggregate(['min', 'max', 'count', 'sum', 'mean', 'median', 'var']).reset_index()\n",
    "df = pd.DataFrame(tmp)\n",
    "df.columns = ['Hour', 'Class', 'Min', 'Max', 'Transactions', 'Sum', 'Mean', 'Median', 'Var']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45632cb-0f34-44b5-a2fb-0962d9f99bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,6))\n",
    "s = sns.lineplot(ax = ax1, x=\"Hour\", y=\"Sum\", data=df.loc[df.Class==0])\n",
    "s = sns.lineplot(ax = ax2, x=\"Hour\", y=\"Sum\", data=df.loc[df.Class==1], color=\"red\")\n",
    "plt.suptitle(\"Total Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964363c4-ce9e-4daf-a859-3deb52164328",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,6))\n",
    "s = sns.lineplot(ax = ax1, x=\"Hour\", y=\"Transactions\", data=df.loc[df.Class==0])\n",
    "s = sns.lineplot(ax = ax2, x=\"Hour\", y=\"Transactions\", data=df.loc[df.Class==1], color=\"red\")\n",
    "plt.suptitle(\"Total Number of Transactions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2f58d-02a2-45a5-898e-6182005fd030",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n",
    "s = sns.boxplot(ax = ax1, x=\"Class\", y=\"Amount\", hue=\"Class\",data=data_df, palette=\"PRGn\",showfliers=True)\n",
    "s = sns.boxplot(ax = ax2, x=\"Class\", y=\"Amount\", hue=\"Class\",data=data_df, palette=\"PRGn\",showfliers=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638fefd-e332-46c2-9c95-138dc28d10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,14))\n",
    "plt.title('Credit Card Transactions features correlation plot (Pearson)')\n",
    "corr = data_df.corr()\n",
    "sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"Reds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3ea9b-3cf0-4a47-9310-c57bd9abb8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = data_df.columns.values\n",
    "\n",
    "i = 0\n",
    "t0 = data_df.loc[data_df['Class'] == 0]\n",
    "t1 = data_df.loc[data_df['Class'] == 1]\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(8,4,figsize=(16,28))\n",
    "\n",
    "for feature in var:\n",
    "    i += 1\n",
    "    plt.subplot(8,4,i)\n",
    "    sns.kdeplot(t0[feature], bw=0.5,label=\"Class = 0\")\n",
    "    sns.kdeplot(t1[feature], bw=0.5,label=\"Class = 1\")\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010cb87-4081-4e86-bdfa-00d2ff94edfa",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c02830-7398-4ae9-a82d-f11931c97261",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Class'\n",
    "predictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n",
    "       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n",
    "       'Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee975982-7d20-4ee2-9974-7cd1531fc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True )\n",
    "train_df, valid_df = train_test_split(train_df, test_size=VALID_SIZE, random_state=RANDOM_STATE, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f88684-c451-4c1f-a1c3-197b11566599",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=NO_JOBS, \n",
    "                             random_state=RANDOM_STATE,\n",
    "                             criterion=RFC_METRIC,\n",
    "                             n_estimators=NUM_ESTIMATORS,\n",
    "                             verbose=False)\n",
    "\n",
    "clf.fit(train_df[predictors], train_df[target].values)\n",
    "preds = clf.predict(valid_df[predictors])\n",
    "\n",
    "tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\n",
    "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
    "\n",
    "plt.figure(figsize = (7,4))\n",
    "plt.title('Features importance',fontsize=14)\n",
    "s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
    "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "plt.show()   \n",
    "\n",
    "roc_auc_score(valid_df[target].values, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da4694-9dbc-46d9-8f67-9b49c6924644",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab2568-161c-4d79-a869-636fe8cb42d0",
   "metadata": {},
   "source": [
    "clf = AdaBoostClassifier(random_state=RANDOM_STATE,\n",
    "                         algorithm='SAMME.R',\n",
    "                         learning_rate=0.8,\n",
    "                             n_estimators=NUM_ESTIMATORS)\n",
    "\n",
    "\n",
    "clf.fit(train_df[predictors], train_df[target].values)\n",
    "\n",
    "preds = clf.predict(valid_df[predictors])\n",
    "\n",
    "tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\n",
    "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
    "plt.figure(figsize = (7,4))\n",
    "plt.title('Features importance',fontsize=14)\n",
    "s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
    "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "plt.show() \n",
    "\n",
    "roc_auc_score(valid_df[target].values, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0ebe9-6fea-4e41-b2f3-a3a0b009d755",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a22d7-96dc-4812-a6dd-ff5f7e38a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_df[predictors], train_df[target].values)\n",
    "dvalid = xgb.DMatrix(valid_df[predictors], valid_df[target].values)\n",
    "dtest = xgb.DMatrix(test_df[predictors], test_df[target].values)\n",
    "\n",
    "#What to monitor (in this case, **train** and **valid**)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "# Set xgboost parameters\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.039\n",
    "params['silent'] = True\n",
    "params['max_depth'] = 2\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.9\n",
    "params['eval_metric'] = 'auc'\n",
    "params['random_state'] = RANDOM_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8626de-1df4-4a97-b3f3-672780283774",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(params, \n",
    "                dtrain, \n",
    "                MAX_ROUNDS, \n",
    "                watchlist, \n",
    "                early_stopping_rounds=EARLY_STOP, \n",
    "                maximize=True, \n",
    "                verbose_eval=VERBOSE_EVAL)\n",
    "\n",
    "preds = model.predict(dtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac5414-eb76-47ab-931b-cdb403596bb2",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e698f-1102-46a9-8e06-87a5745a5005",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'binary',\n",
    "          'metric':'auc',\n",
    "          'learning_rate': 0.05,\n",
    "          'num_leaves': 7,  # we should let it be smaller than 2^(max_depth)\n",
    "          'max_depth': 4,  # -1 means no limit\n",
    "          'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "          'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "          'subsample': 0.9,  # Subsample ratio of the training instance.\n",
    "          'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "          'colsample_bytree': 0.7,  # Subsample ratio of columns when constructing each tree.\n",
    "          'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "          'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "          'nthread': 8,\n",
    "          'verbose': 0,\n",
    "          'scale_pos_weight':150, # because training data is extremely unbalanced \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e63dc-81ec-4ad7-8a38-173b6bf8802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(train_df[predictors].values, \n",
    "                     label=train_df[target].values,\n",
    "                     feature_name=predictors)\n",
    "\n",
    "dvalid = lgb.Dataset(valid_df[predictors].values,\n",
    "                     label=valid_df[target].values,\n",
    "                     feature_name=predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665bad31-0008-4c1e-8ed7-fbcf2baeb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_results = {}\n",
    "\n",
    "model = lgb.train(params, \n",
    "                  dtrain, \n",
    "                  valid_sets=[dtrain, dvalid], \n",
    "                  valid_names=['train','valid'], \n",
    "                  evals_result=evals_results, \n",
    "                  num_boost_round=MAX_ROUNDS,\n",
    "                  early_stopping_rounds=2*EARLY_STOP,\n",
    "                  verbose_eval=VERBOSE_EVAL, \n",
    "                  feval=None)\n",
    "\n",
    "preds = model.predict(test_df[predictors])\n",
    "\n",
    "roc_auc_score(test_df[target].values, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b77389-671c-455c-b5bd-1396b0221a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross Validation\n",
    "\n",
    "kf = KFold(n_splits = NUMBER_KFOLDS, random_state = RANDOM_STATE, shuffle = True)\n",
    "\n",
    "# Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "n_fold = 0\n",
    "for train_idx, valid_idx in kf.split(train_df):\n",
    "    train_x, train_y = train_df[predictors].iloc[train_idx],train_df[target].iloc[train_idx]\n",
    "    valid_x, valid_y = train_df[predictors].iloc[valid_idx],train_df[target].iloc[valid_idx]\n",
    "    \n",
    "    evals_results = {}\n",
    "    model =  LGBMClassifier(\n",
    "                  nthread=-1,\n",
    "                  n_estimators=2000,\n",
    "                  learning_rate=0.01,\n",
    "                  num_leaves=80,\n",
    "                  colsample_bytree=0.98,\n",
    "                  subsample=0.78,\n",
    "                  reg_alpha=0.04,\n",
    "                  reg_lambda=0.073,\n",
    "                  subsample_for_bin=50,\n",
    "                  boosting_type='gbdt',\n",
    "                  is_unbalance=False,\n",
    "                  min_split_gain=0.025,\n",
    "                  min_child_weight=40,\n",
    "                  min_child_samples=510,\n",
    "                  objective='binary',\n",
    "                  metric='auc',\n",
    "                  silent=-1,\n",
    "                  verbose=-1,\n",
    "                  feval=None)\n",
    "    model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric= 'auc', verbose= VERBOSE_EVAL, early_stopping_rounds= EARLY_STOP)\n",
    "    \n",
    "    oof_preds[valid_idx] = model.predict_proba(valid_x, num_iteration=model.best_iteration_)[:, 1]\n",
    "    test_preds += model.predict_proba(test_df[predictors], num_iteration=model.best_iteration_)[:, 1] / kf.n_splits\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = predictors\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    \n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "    del model, train_x, train_y, valid_x, valid_y\n",
    "    gc.collect()\n",
    "    n_fold = n_fold + 1\n",
    "train_auc_score = roc_auc_score(train_df[target], oof_preds)\n",
    "print('Full AUC score %.6f' % train_auc_score)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
